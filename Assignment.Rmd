---
title: "Practical Machine Learning"
author: "Pilot Gtec EFTL"
date: "23 January 2015"
output: html_document
---
##Excutive Summary

In this project, the goal is to accurately predict the manner in which individuals using wearable gadgets performed their exercises, which is indicated in the `classe` variable in the datasets provided by [Groupware][1]. Two types of data are given in the class: (1) training and (2) test. The training set is utilized to set-up a predictive model. Four predictive models are explored herewith:

- Recursive Partitioning without Pre-processing (**PM1**)
- Recursive Partitioning with Pre-processing (**PM2**)
- Random Forests  without Pre-processing (**PM3**)
- Random Forests with Pre-processing (**PM4**)

We find that **PM3** and **PM4** give high prediction accuracy values compared to the other two. Finally, we use both **PM3** and **PM4** to predict the ``classe`` values in the test set. Both methods result to the same prediction.

[1]: http://groupware.les.inf.puc-rio.br/har "Groupware"


###Getting and Cleaning Data

- Find `NA` values.
- Drop columns that are not complete.
- Drop columns that are not predictor variables.

```{r}
dat_training <- read.csv("pml-training.csv", header=TRUE, na.strings=c("NA",""))
dat_test <- read.csv("pml-testing.csv", header=TRUE, na.strings=c("NA",""))
```

Drop columns that are not complete.
```{r}
dat_training_trimmed <- dat_training[, (colSums(is.na(dat_training)) == 0)]
dat_test_trimmed <- dat_test[, (colSums(is.na(dat_training)) == 0)]
```

From here, we drop the first seven (7) columns `r names(dat_training_trimmed)[1:7]` since they are not feature variables.

```{r echo=FALSE, warning=FALSE, message=FALSE}
library(dplyr)
library(caret)
```

```{r, warning=FALSE, message=FALSE}
dat_training_trimmed <- select(dat_training_trimmed, roll_belt:classe)[,]
dat_test_trimmed <- select(dat_test_trimmed, roll_belt:problem_id)[,]
```

###Training Set

Note that there are a total of `r nrow(dat_training_trimmed)` cases for the training set. Since the number of cases for the training set is huge, we can create subsets of these from which we can run and validate our predictive models. We create two subsets: `train1` and `train2`. 

```{r warning=FALSE, message=FALSE}
set.seed(222)
ids_train = createDataPartition(y=dat_training_trimmed$classe, p=0.50, list = FALSE)
subtrain1 = dat_training_trimmed[ids_train,]
subtrain2 = dat_training_trimmed[-ids_train,]
```

We further subdivide datasets `train1` (`r nrow(subtrain1)` entries) and `train2` (`r nrow(subtrain2)` entries) into *training* (80%) and *validation* (20%) sets for training and validation, respectively.

```{r warning=FALSE, message=FALSE}
set.seed(222)
ids_train1 = createDataPartition(y = subtrain1$classe, p=0.80, list=FALSE)
subtrain1_training = subtrain1[ids_train1,]
subtrain1_validation = subtrain1[-ids_train1,]

set.seed(222)
ids_train2 = createDataPartition(y = subtrain2$classe, p=0.80, list=FALSE)
subtrain2_training = subtrain2[ids_train2,]
subtrain2_validation = subtrain2[-ids_train2,]
```

###Predictive Models

Four predictive models are performed in this project.

- Recursive Partitioning without Pre-processing (**PM1**)
- Recursive Partitioning with Pre-processing (**PM2**)
- Random Forests  without Pre-processing (**PM3**)
- Random Forests with Pre-processing (**PM4**)

For **PM1** and **PM2**, we use a *recursive partitioning* model (method: `rpart`), while for **PM3** and **PM4**, we use *random forests*. Finally for **PM2** and **PM4**, we preprocess the sets ("center" and "scale").

For illustration, here's a sample chunk of code for one predictive model. For **PM3** and **PM4**, 
`method="rf"`.

```{r warning=FALSE, message=FALSE}
####Recursive Partitioning without Pre-processing
set.seed(222)
PM1 <- train(subtrain1_training$classe ~ ., data = subtrain1_training, method="rpart", 
                trControl=trainControl(method = "cv", number = 5))
predictions1 <- predict(PM1, newdata = subtrain1_validation)
cmatrix1 <- confusionMatrix(predictions1, subtrain1_validation$classe)
ct_accuracy1 <- cmatrix1$overall[1]
```


```{r warning=FALSE, message=FALSE, echo=FALSE, cache=TRUE}

set.seed(222)
PM1 <- train(subtrain2_training$classe ~ ., data = subtrain2_training, method="rpart", 
                trControl=trainControl(method = "cv", number = 5))
predictions2 <- predict(PM1, newdata = subtrain2_validation)
cmatrix2 <- confusionMatrix(predictions2, subtrain2_validation$classe)
ct_accuracy2 <- cmatrix2$overall[1]

####Recursive Partitioning with Pre-processing
set.seed(222)
PM2 <- train(subtrain1_training$classe ~ ., data = subtrain1_training, 
             preProcess=c("center", "scale"), method="rpart",
             trControl=trainControl(method = "cv", number = 5))
predictions1 <- predict(PM2, newdata = subtrain1_validation)
cmatrix1 <- confusionMatrix(predictions1, subtrain1_validation$classe)
ct_accuracy3 <- cmatrix1$overall[1]

set.seed(222)
PM2 <- train(subtrain2_training$classe ~ ., data = subtrain2_training, 
             preProcess=c("center", "scale"), method="rpart",
             trControl=trainControl(method = "cv", number = 5))
predictions2 <- predict(PM2, newdata = subtrain2_validation)
cmatrix2 <- confusionMatrix(predictions2, subtrain2_validation$classe)
ct_accuracy4 <- cmatrix2$overall[1]

####Random Forests w/
set.seed(222)
PM31 <- train(subtrain1_training$classe ~ ., method="rf", data=subtrain1_training,
             trControl=trainControl(method = "cv", number = 5))
predictions1 <- predict(PM31, newdata = subtrain1_validation)
cmatrix1 <- confusionMatrix(predictions1, subtrain1_validation$classe)
rf_accuracy1 <- cmatrix1$overall[1]

set.seed(222)
PM32 <- train(subtrain2_training$classe ~ ., method="rf",  
                data=subtrain2_training, trControl=trainControl(method = "cv", number = 5))
predictions2 <- predict(PM32, newdata = subtrain2_validation)
cmatrix2 <- confusionMatrix(predictions2, subtrain2_validation$classe)
rf_accuracy2 <- cmatrix2$overall[1]

####Random Forests w/o
set.seed(222)
PM41 <- train(subtrain1_training$classe ~ ., method="rf", 
              preProcess=c("center", "scale"), 
              data=subtrain1_training, 
              trControl=trainControl(method = "cv", number = 5))
predictions1 <- predict(PM41, newdata = subtrain1_validation)
cmatrix1 <- confusionMatrix(predictions1, subtrain1_validation$classe)
rf_accuracy3 <- cmatrix1$overall[1]

PM42 <- train(subtrain2_training$classe ~ ., method="rf", 
              preProcess=c("center", "scale"), 
              data=subtrain2_training, 
              trControl=trainControl(method = "cv", number = 5))
predictions2 <- predict(PM42, newdata = subtrain2_validation)
cmatrix2 <- confusionMatrix(predictions2, subtrain2_validation$classe)
rf_accuracy4 <- cmatrix2$overall[1]
```

####Model Accuracies


```{r, echo=FALSE, warning=FALSE, message=FALSE}
error1 <- 1 - rf_accuracy3
error2 <- 1 - rf_accuracy4
m <- mean(c(error1, error2))
```

We note that **PM4** gives the highest accuracies for both subsets: `r rf_accuracy3` and `r rf_accuracy4`, with out-of-sample errors `r error1` and `r error2`, respectively, or an average of `r m`. 

```{r, echo=FALSE, warning=FALSE, message=FALSE, results='asis'}
library(xtable)
dat <- data.frame( "PM1"=c(ct_accuracy1, ct_accuracy2), 
                   "PM2"=c(ct_accuracy3, rf_accuracy4),
                   "PM3"=c(rf_accuracy1, rf_accuracy2),
                   "PM4"=c(rf_accuracy3, rf_accuracy4))
rownames(dat) <- c("Subset 1", "Subset 2")
print(xtable(dat, digits=3, caption ="Summary of Accuracies"), type="html")
```


Therefore, for the test dataset provided herewith, we utilize random forests to predict the `classe` for each of the entry. 


```{r warning=FALSE, message=FALSE}
predictionsfinal <- predict(PM41, newdata = dat_test_trimmed)
print (predictionsfinal)
predictionsfinal <- predict(PM42, newdata = dat_test_trimmed)
print (predictionsfinal)
predictionsfinal <- predict(PM31, newdata = dat_test_trimmed)
print (predictionsfinal)
predictionsfinal <- predict(PM32, newdata = dat_test_trimmed)
print (predictionsfinal)
```

For completeness, here are the predictions for the recursive partitioning methods.

```{r warning=FALSE, message=FALSE}
predictions <- predict(PM1, newdata = dat_test_trimmed)
print (predictions)

predictions <- predict(PM2, newdata = dat_test_trimmed)
print (predictions)
```
